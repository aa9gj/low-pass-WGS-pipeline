# GATK GenotypeGVCFs Workflow by Chromosome (SLURM Optimized)

This SLURM-enabled Bash script automates the joint genotyping of gVCFs stored in a GATK GenomicsDB workspace. It processes data one chromosome at a time, making it an efficient solution for generating VCF files for large cohorts on High-Performance Computing (HPC) clusters.

---

## What It Does

This script runs GATK's `GenotypeGVCFs` tool for each specified chromosome. It takes the consolidated gVCF data from a GenomicsDB workspace and performs joint genotyping, which is the process of simultaneously calling genotypes across all samples at every variant site.

Here's a breakdown of the steps:

1.  **Environment Setup**: Loads the required Java module (Java 17.0.9).
2.  **Define Paths**: Sets up paths for the reference genome, the GenomicsDB directories, and the output VCF files.
3.  **Chromosome Selection**: Based on the SLURM array task ID, it selects a specific chromosome from a predefined list (`CHROMS`), ensuring that each array job processes a distinct genomic region.
4.  **Output Directory Creation**: Creates the necessary output directory structure for the resulting VCF files.
5.  **GenotypeGVCFs Execution**: Runs `gatk GenotypeGVCFs`, instructing it to:
    * Use the specified **reference genome**.
    * Read input from the **GenomicsDB workspace** corresponding to the current chromosome.
    * Write the joint-genotyped VCF output to a **compressed VCF file** (`.vcf.gz`).

---

## How to Use It

### Prerequisites

* **GATK**: Ensure GATK is installed and available in your environment's `PATH`.
* **Java 17.0.9**: The script specifically loads this version. Adjust `ml java/17.0.9` if your cluster uses a different module name or GATK requires a different Java version.
* **SLURM Workload Manager**: This script is designed for SLURM-managed clusters.
* **Reference Genome**: The FASTA file (`.fa`) used for alignment and GenomicsDB creation.
* **GenomicsDB Workspaces**: You must have pre-built GenomicsDB workspaces for each chromosome, generated by `GenomicsDBImport` (e.g., using a script like the `GDB_chr` one). These should be located in the directory specified by `DBDIR`.

### Setup

1.  **Define `REF` Path**: In the script, change `REF=<ref_fasta>` to the **actual full path** of your reference genome FASTA file.

2.  **Define `DBDIR` Path**: Change `DBDIR=/path/to/genomicsdb` to the **actual full path** of the parent directory containing your chromosome-specific GenomicsDB workspaces (e.g., if your workspaces are `/data/genomicsdb/chr1`, `/data/genomicsdb/chrX`, then `DBDIR` would be `/data/genomicsdb`).

3.  **Define `OUT_VCF` Path**: Adjust `OUT_VCF=/path/to/output/genotypes/${CHR}.vcf.gz` to specify the desired output directory for your final VCF files. The script will automatically create this directory if it doesn't exist.

4.  **Adjust `CHROMS` Array and SLURM Array Index**:
    * The `CHROMS` array in the script currently lists chromosomes `chr1` through `chr38` and `chrX`. **Ensure this array matches the exact names and order of chromosomes for which you have GenomicsDB workspaces.**
    * The `#SBATCH --array=1-39` line **must be kept in sync** with the number of chromosomes in your `CHROMS` array. If you have 38 autosomes and chrX, `1-39` is correct (39 total elements). If you include other chromosomes (e.g., `chrY`, `chrMT`), you'll need to add them to both `CHROMS` and adjust the `--array` range accordingly.

5.  **Adjust SLURM Resources (Optional but Recommended)**:
    * `--time=99:00:00`: This sets a very generous time limit. Joint genotyping can be computationally intensive, especially for large cohorts and dense chromosomes. Adjust this based on your expected runtime.
    * `--cpus-per-task=4`: 4 CPU cores are allocated per task. `GenotypeGVCFs` can utilize multiple threads. Adjust as needed based on your cluster's resources and GATK's performance.
    * `--mem=64G`: 64GB of memory is allocated per task. This tool can be memory-intensive; ensure you provide enough.

### Running the Script

1.  **Save the script**: Save the provided Bash script content to a file, for example, `run_genotype_gvcfs.sh`.
2.  **Submit the job**: From your cluster's login node, navigate to the directory where you saved `run_genotype_gvcfs.sh`, and submit the job to SLURM:
    ```bash
    sbatch run_genotype_gvcfs.sh
    ```

---

## Output

### Log Files

SLURM will create log files in the directory from which you submit the job, named after the job ID and array task ID:

* `genoGVCF_chr_JOBID_ARRAYINDEX.out`: Standard output for each chromosome's genotyping process.
* `genoGVCF_chr_JOBID_ARRAYINDEX.err`: Standard error for each chromosome's genotyping process.

### Genotyped VCF Files

For each chromosome, a compressed VCF file will be generated in the path specified by `OUT_VCF`. These files will contain the joint-genotyped variant calls for all samples for that specific chromosome.

* `/path/to/output/genotypes/chr1.vcf.gz`
* `/path/to/output/genotypes/chr2.vcf.gz`
* ...
* `/path/to/output/genotypes/chrX.vcf.gz`

---

## Important Notes

* **GenomicsDB Workspace Integrity**: Ensure your GenomicsDB workspaces (created by `GenomicsDBImport`) are complete and uncorrupted before running this step. `GenotypeGVCFs` relies heavily on these databases.
* **Java Memory**: The Java option `-Xmx12g` sets the maximum heap size for the Java Virtual Machine. Ensure this value is less than the allocated `--mem` (`64G`) to leave room for other system processes. You might need to adjust this value based on the size and complexity of your dataset.
* **Downstream Merging**: After all chromosome-specific VCFs are generated, you will typically need to merge them into a single genome-wide VCF file, usually using `picard GatherVcfs` or `gatk GatherVcfs`.
* **Array Management**: It's absolutely critical that the `--array` range in your SLURM headers precisely matches the number of elements in your `CHROMS` array, and that `CHROMS` accurately reflects the chromosomes for which you have GenomicsDB workspaces. Misconfiguration can lead to failed jobs or skipped chromosomes.
